---
title: Bias Toolkit
subtitle: Equipping the user with tools that help mitigate and correct sources of bias in federal data
excerpt: Bias in federal data is not a new issue, but the importance of addressing it is compounded by the increasing application of machine learning (ML) models. This toolkit is a collection of products that addresses bias in hiring, documentation, and data generation.
permalink: /projects/bias-toolkit
img_alt_text: 
agency_partner:
university_partner:
  entities:
status: Ongoing
project_url: 
featured: true
portfolio: bias
---
<p>
Bias in federal data is not a new issue, but the importance of addressing it is compounded by the increasing application of machine learning (ML) models being built using biased training data. Many issues of bias in federal data can be partially mitigated by solutions that address issues in the planning, collection, analysis, and dissemination of data. The toolkit represents the Census Bureau’s leadership in data equity and emerging technologies and seeks to extend and facilitate more conversation and tooling across the Federal Statistical System. 
<br>
<br>
The toolkit comprises three tools: ableist language detector, data generation tool, and model card generator. This tool could impact the hiring of thousands of federal employees and result in a more diverse and inclusive federal workforce, enable more expansive and principled ethical use of externally acquired tools and models, and reduce bias by exploring a model’s ability to perform across sensitive classes.

</p>
