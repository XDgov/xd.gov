---
title: Combating Bias in AI
subtitle: Building a product that automatically detects bias in datasets that could lead to incorrect, systematically biased predictions.
excerpt: A major risk in building data-driven applications is susceptibility to biases in data. This project seeks to develop scalable solutions to help those using federal data to identify sources of biased training data.
seo_excerpt: A product that automatically detects bias in datasets that could lead to incorrect, systematically biased predictions.
permalink: /projects/combating-bias-in-ai/
image: /assets/img/projects/combating-bias-in-ai/combating-bias-in-ai-og.png
img_alt_text: An isometric 3 by 5 grid is formed by square blocks. 4 blocks in the bottom-right are joined by a line and are in a different color demonstrating a focus, or bias, to the bottom-right of the grid.
partners:
  entities:
    - { url: 'https://10x.gsa.gov', name: 'General Services Administration - 10x' }
    - { url: 'https://www.dol.gov/agencies/odep', name: 'Department of Labor - Office of Disability Employment Policy' }
status: Ongoing
featured: false
portfolio: bias
active: false
---
<p>
  A major risk in building data-driven applications, including those that use machine learning methods, is susceptibility to biases in data.  Even the best models can fail if the distribution of out-of-sample data differs significantly from the distribution of the data that was used to train or validate the model. Also, machine learning algorithms trained on biased data can sometimes amplify those biases. To address this problem, we are developing a set of scalable software products and companion training material to help those using federal data systematically identify sources of biased training data.
</p>